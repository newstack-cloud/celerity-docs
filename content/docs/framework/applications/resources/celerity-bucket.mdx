---
title: Celerity Bucket
description: The Celerity bucket resource type
---

**`celerity/bucket`**

**Spec Version:** `v2025-12-01-draft`  
**Ecosystem Compatibility:** v0 (Current) / v1 (Preview)

**blueprint transform:** `celerity-2025-12-01-draft`

<Callout title="Ecosystem Compatibility" type="info">
- **v0 (Current)**: AWS only, with support for Amazon S3.
- **v1 (Preview)**: Multi-cloud with support for Amazon S3, Google Cloud Storage and Azure Blob Storage.

Read more about Celerity versions [here](/docs/framework/versions).
</Callout>

The `celerity/bucket` resource type defines an object storage bucket that can be used to store files and other data for a Celerity application.

## Specification

The specification is the structure of the resource definition that comes under the `spec` field of the resource in a blueprint.
The rest of this section lists fields that are available to configure the `celerity/bucket` resource followed by examples of different configurations for the resource and how buckets are implemented in target environments along with additional documentation.

<Callout title="Feature Availability" type="info">
- âœ… **Available in v0** - Features currently supported
- ðŸ”„ **Planned for v0** - Features coming in future v0 evolution
- ðŸš€ **Planned for v1** - Features coming in v1 release
</Callout>

### name

A unique name to use for the bucket.
If a name is not provided, a unique name will be generated for the bucket based on the blueprint that the bucket is defined in.

<Callout title="Warning" type="warning">
Depending on the target environment, when you specify a name, you may not be able to perform updates that require replacing the bucket, if you need to replace the bucket, you may need to specify a new name.
</Callout>

**type**

string

### encryption

The encryption configuration for the bucket.
When not provided, default encryption settings will be used for the target environment.

âœ… **Available in v0**

**type**

[encryptionConfiguration](#encryptionconfiguration)

### cors

[CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) configuration for objects in a bucket.

âœ… **Available in v0**

**type**

[corsConfiguration](#corsconfiguration)

### lifecycle

Lifecycle configuration for objects in the bucket.

âœ… **Available in v0**

**type**

[lifecycleConfiguration](#lifecycleconfiguration)

### logging

Logging configuration for the bucket.

âœ… **Available in v0**

**type**

[loggingConfiguration](#loggingconfiguration)

### versioning

Versioning configuration used to enable versioning for objects in the bucket.

âœ… **Available in v0**

**type**

[versioningConfiguration](#versioningconfiguration)

### replication

Replication configuration for the bucket.
This is used primarily for cross-region replication of objects in the bucket.

The replication configuration for Celerity buckets is a simplified approach that is designed to work across multiple target environments. In this simplified model, you can choose the regions to replicate to.

Some configuration will be specific to target environments and will need to be specified in the [app deploy configuration](#app-deploy-configuration).

âœ… **Available in v0**

**type**

[replicationConfiguration](#replicationconfiguration)

### website

Configuration for hosting a static website in the bucket.
Website configuration is a simplified model that is designed to work across multiple target environments.
You can specify the index and error documents for the website, more advanced configuration such as redirects and routing rules are not supported in this simplified model.

âœ… **Available in v0**

**type**

[websiteConfiguration](#websiteconfiguration)

## Annotations

There are no annotations required for linking other resources to a `celerity/bucket` resource or modifying the behaviour of a bucket resource.

`linkSelector.byLabel` can be used to target buckets from other resource types.

## Outputs

Outputs are computed values that are accessible via the `{resourceName}.spec.*` field accessor in a blueprint substitution.
For example, if the resource name is `myBucket`, the output would be accessible via `${myBucket.spec.id}`.

### id

The ID of the created object storage bucket in the target environment.

**type**

string

**examples**

`arn:aws:s3:::my-bucket` (AWS)

`projects/my-project/buckets/my-bucket` (Google Cloud)

`my-bucket` (Azure)

## Data Types

### encryptionConfiguration

Encryption configuration for the bucket.

<FieldsHeading />

<FieldHeading fieldName="encryptionKeyId" />

The ID of the encryption key to use for encrypting objects in the bucket.

**field type**

string

**examples**

`arn:aws:kms:us-west-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab` (AWS)

___

<FieldHeading fieldName="encryptionAlgorithm" />

The algorithm to use for encryption.

For example, in AWS, you can use `AES256` or `aws:kms`.

This is only supported in some target environments.

**field type**

string

**examples**

`arn:aws:kms:us-west-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab` (AWS)

___

### corsConfiguration

<FieldsHeading />

<FieldHeading fieldName="corsRules" />

An array of CORS rules to apply to the bucket.

**field type**

array[[corsRule](#corsrule)]

___

### corsRule

<FieldsHeading />

<FieldHeading fieldName="id" />

A unique identifier to be used for the rule.

**field type**

string

___

<FieldHeading fieldName="allowedOrigins" />

An array of allowed origins that your customers will be able to access the bucket from.

**field type**

array[string]

**examples**

`["http://example.com", "https://example.com"]`

___

<FieldHeading fieldName="allowedHeaders" />

An array of allowed headers that are specified in the `Access-Control-Request-Headers` header.
These headers are allowed in preflight OPTIONS requests.
In response to a preflight request, the object storage service will return the requested headers that are allowed.

**field type**

array[string]

**examples**

`["Content-Type", "Authorization"]`

___

<FieldHeading fieldName="allowedMethods" />

An array of HTTP methods that are allowed for the bucket across origins.

**field type**

array[string]

**examples**

`["GET", "POST"]`

___

<FieldHeading fieldName="exposedHeaders" />

An array of headers in the response that you want customers to be able to access from their applications.

**field type**

array[string]

**examples**

`["Content-Type"]`

___

<FieldHeading fieldName="maxAge" />

Time in seconds that the browser is to cache the preflight response for the requested resource
in the bucket.
This must be a positive integer, equal to or greater than 0.

**field type**

integer

___

### lifecycleConfiguration

<FieldsHeading />

<FieldHeading fieldName="rules" />

An array of lifecycle rules to apply to the bucket.

<Callout title="Warning" type="warning">
Some provider-specific fields in lifecycle rule configurations may be excluded due to the lack
of an equivalent across all target environments.
</Callout>

**field type**

array[[lifecycleRule](#lifecyclerule)]

___

### lifecycleRule

<FieldsHeading />

<FieldHeading fieldName="id (required)" />

A unique identifier to be used for the rule.

**field type**

string

___

<FieldHeading fieldName="enabled (required)" />

Whether or not the rule is enabled.

**field type**

boolean

___

<FieldHeading fieldName="abortIncompleteMultipartUpload" />

Specifies the number of days after initiating a multipart upload that the multipart upload must be completed. If the multipart upload is not completed within the specified number of days, the object storage service will abort the multipart upload and delete the parts that were uploaded.

This field is supported by the following target environments:

- AWS (Amazon S3)
- Google Cloud (Cloud Storage)

**field type**

[abortIncompleteMultipartUploadConfig](#abortincompletemultipartuploadconfig)

___

<FieldHeading fieldName="expirationDate" />

Specifies the date after which objects matching the rule in the bucket will expire.
This is expected to be an ISO 8601 date string.

This field is supported by the following target environments:

- AWS (Amazon S3)

**field type**

string

**examples**

`2024-07-22T00:00:00Z`

___

<FieldHeading fieldName="expirationInDays" />

Specifies the number of days after the creation date of an object that the object will expire.

This field is supported by the following target environments:

- AWS (Amazon S3)
- Google Cloud (Cloud Storage)
- Azure (Blob Storage)

**field type**

integer

**examples**

`365`

___

<FieldHeading fieldName="noncurrentVersionExpiration" />

Specifies when noncurrent versions of objects in the bucket will expire.

This field is supported by the following target environments:

- AWS (Amazon S3)
- Google Cloud (Cloud Storage)
- Azure (Blob Storage)

**field type**

[noncurrentVersionExpirationConfig](#noncurrentversionexpirationconfig)

**examples**

`365`

___

<FieldHeading fieldName="noncurrentVersionTransitions" />

Specifies when noncurrent versions are transitioned to a different storage class.
Storage classes are simplified to the closest equivalent to `hot`, `cool` and `archive` storage classes,
this does not give precise control over the exact storage class in target environments with more granular storage classes.

This field is supported by the following target environments:

- AWS (Amazon S3)
- Google Cloud (Cloud Storage)
- Azure (Blob Storage)

**field type**

array[[noncurrentVersionTransitionConfig](#noncurrentversiontransitionconfig)]

**examples**

`365`

___

<FieldHeading fieldName="prefix" />

Specifies a prefix for the rule to apply to objects in the bucket.

**field type**

string

**examples**

`logs/`

___

<FieldHeading fieldName="transitions" />

Specifies when objects in the bucket will transition to a different storage class.
Storage classes are simplified to the closest equivalent to `hot`, `cool` and `archive` storage classes,
this does not give precise control over the exact storage class in target environments with more granular storage classes.

This field is supported by the following target environments:

- AWS (Amazon S3)
- Google Cloud (Cloud Storage)
- Azure (Blob Storage)

**field type**

array[[transitionConfig](#transitionconfig)]

**examples**

`365`


### abortIncompleteMultipartUploadConfig

<FieldsHeading />

<FieldHeading fieldName="daysAfterInitiation" />

The number of days after initiating a multipart upload that the multipart upload must be completed.

**field type**

integer

**examples**

`7`

___

### noncurrentVersionExpirationConfig

<FieldsHeading />

<FieldHeading fieldName="noncurrentDays" />

The number of days after which noncurrent versions of objects in the bucket will expire.

**field type**

integer

**examples**

`30`

___

### noncurrentVersionTransitionConfig

<FieldsHeading />

<FieldHeading fieldName="targetStorageClass (required)" />

The storage class to transition noncurrent versions of objects to.

See [Storage Class Mappings](#storage-class-mappings) for more information on how provider-specific storage classes are mapped to the simplified model.

**field type**

string

**allowed values**

`cool` | `archive`

___

<FieldHeading fieldName="transitionInDays (required)" />

The number of days after which noncurrent versions of objects in the bucket will be transitioned to the target storage class.

**field type**

integer

___

### transitionConfig

<FieldsHeading />

<FieldHeading fieldName="targetStorageClass (required)" />

The storage class to transition objects to.

See [Storage Class Mappings](#storage-class-mappings) for more information on how provider-specific storage classes are mapped to the simplified model.

**field type**

string

**allowed values**

`cool` | `archive`

___

<FieldHeading fieldName="transitionInDays (required)" />

The number of days after which objects in the bucket will be transitioned to the target storage class.

**field type**

integer

___

### loggingConfiguration

<FieldsHeading />

<FieldHeading fieldName="destinationBucket" />

The name of the bucket to save server access log files to.
By default, logs will be saved to the same bucket.

**field type**

string

**examples**

`my-logs-bucket`

___

<FieldHeading fieldName="logFilePrefix" />

The prefix to apply to log files saved in the destination bucket.
If you store log files from multiple buckets in a single bucket, you can use this prefix to differentiate between them.

**field type**

string

**examples**

`logs/`

___

### versioningConfiguration

<FieldsHeading />

<FieldHeading fieldName="status" />

The status of versioning for the bucket.
This can be set to `Enabled` to enable versioning for the bucket, or `Suspended` to suspend versioning.
When versioning is suspended, new objects will not have versions created, but existing versions will still be retained.

For Google Cloud, `Suspended` is equivalent to a `Disabled` object versioning status with a soft delete status set to `Enabled`.

For Azure Blob Storage, `Suspended` is equivalent to disabling blob versioning for the bucket, which leaves the existing versions intact, see [Azure Blob Storage versioning](https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-overview#enable-or-disable-blob-versioning) for more information.

By default, if versioning configuration is not provided, versioning will be disabled.

**field type**

string

**allowed values**

`Enabled` | `Suspended`

**examples**

`Enabled`

___

### replicationConfiguration

<FieldsHeading />

<FieldHeading fieldName="enabled" />

Whether or not replication is enabled for the bucket.

**field type**

boolean

___

<FieldHeading fieldName="regions" />

The regions to replicate objects in the bucket to.

The region strings are expected to be in the format of the target environment's region identifiers, for example:

- AWS: `us-west-2`
- Google Cloud `US-WEST2`
- Azure: `westus2`

<Callout title="Google Cloud Dual-Region Replication" type="warning">
For Google Cloud, you can only specify a single region to replicate to, as Celerity uses the dual-region replication approach for Google Cloud Storage.
</Callout>

**field type**

array[string]

**examples**

```json
["us-west-2", "us-east-1"]
```

___

### websiteConfiguration

<FieldsHeading />

<FieldHeading fieldName="mainPageDocument" />

The name of the main page document for the static website hosted in the bucket.

**field type**

string

**examples**

`index.html`

___

<FieldHeading fieldName="notFoundDocument" />

The name of the document to return when a requested object is not found in the bucket.
This is typically a custom 404 page that you can use to provide a better user experience when a requested object is not found.

For the AWS target environments, this will be used as the error document for the static website hosted in the bucket that is a catch-all for errors beyond 404 not found errors.

**field type**

string

**examples**

`404.html`

___

## Linked From

### `celerity/handler`

When a handler links out to a bucket, it will be configured with permissions and environment variables that enable the handler to interact with the bucket. If a `celerity/config` resource is associated with the handler or the application that it is a part of, the bucket configuration will be added to the config/secret store instead of environment variables. You can use guides and templates to get an intuition for how to source the configuration and interact with object storage services using the handlers SDK.

<Callout title="Opting out of the handlers SDK for buckets" type="warning">
You don't have to use the handlers SDK abstraction for buckets,
you can also grab the populated configuration directly and interact directly with the SDK for the object storage service for the chosen target environment. Doing so will require application code changes if you decide to switch target environments.
</Callout>

âœ… **Available in v0**

[Read more about Celerity Handlers](/docs/framework/applications/resources/celerity-handler)

## Links To

### `celerity/queue`

When a bucket is linked to a queue, the queue will be configured to receive notifications from the bucket for events such as object creation, deletion, and updates. This is useful for making events flow through a queue for processing by handlers in an application where the queue can be used to control the flow of events and ensure that they are processed in a reliable manner.

In cases where you deploy your application to a target environment that is not FaaS-based[^1], a queue will be used to receive notifications from the bucket that the Celerity runtime will poll for events and trigger handlers accordingly.

âœ… **Available in v0**

[Read more about Celerity Queues](/docs/framework/applications/resources/celerity-queue)

### `celerity/topic`

When a bucket is linked to a topic, the topic will be configured to receive notifications from the bucket for events such as object creation, deletion, and updates. This is useful for publishing events to a topic that can be subscribed to by consumers such as handlers in applications of the `celerity/consumer` resource type.

âœ… **Available in v0**

[Read more about Celerity Topics](/docs/framework/applications/resources/celerity-topic)

### `celerity/consumer`

When a bucket is linked to a consumer, the consumer will be configured to receive notifications from the bucket for events such as object creation, deletion, and updates. This is useful for processing events that can then perform actions based on the events received from the bucket.

For FaaS-based target environments, the handlers configured for the consumer will be triggered directly through a rule in the cloud provider's event system (e.g. Amazon EventBridge). To gain greater control over throughput and processing of events, you can link the bucket to a queue or topic and have the application consume events from there.

âœ… **Available in v0**

[Read more about Celerity Consumers](/docs/framework/applications/resources/celerity-consumer)

### `celerity/workflow`

When a bucket is linked to a workflow, a workflow execution will be triggered when an event occurs in the bucket, such as an object being created, deleted, or updated. For FaaS-based target environments, the notification will be used to trigger an execution of the cloud provider's workflow service (e.g. AWS Step Functions). For non-FaaS target environments, an intermediary serverless function will be triggered by the bucket event to start the workflow execution by calling the API of your workflow application provided by the Celerity Workflow Runtime.

ðŸš€ **Planned for v1** - Support for workflows is planned for v1, they may become available in a future v0 evolution.

[Read more about Celerity Workflows](/docs/framework/applications/resources/celerity-workflow)

## Examples

### Basic Bucket Configuration

```yaml
version: 2025-05-12
transform: celerity-2025-12-01-draft
resources:
  myAppBucket:
    type: "celerity/bucket"
    metadata:
      displayName: My App Bucket
    spec:
      name: "my-app-bucket"
```

### Complex Bucket Configuration

```yaml
version: 2025-05-12
transform: celerity-2025-12-01-draft
variables:
    encryptionKeyId:
        type: string
        description: "The ID of the encryption key to use for the bucket."
    encryptionAlgorithm:
        type: string
        description: "The algorithm to use for encryption, e.g. 'AES256' or 'aws:kms'."
        default: "aws:kms"
    logsBucket:
        type: string
        description: "The name of the bucket to store logs in."

resources:
    myAppBucket:
        type: "celerity/bucket"
        metadata:
            displayName: My App Bucket
        spec:
            name: "my-app-bucket"
            encryption:
                encryptionKeyId: "${variables.encryptionKeyId}"
                encryptionAlgorithm: "${variables.encryptionAlgorithm}"
            cors:
                corsRules:
                    - id: "cors-rule-1"
                      allowedOrigins: ["http://example.com", "https://example.com"]
                      allowedHeaders: ["Content-Type", "Authorization"]
                      allowedMethods: ["GET", "POST"]
                      exposedHeaders: ["Content-Type"]
                      maxAge: 3600
            lifecycle:
                rules:
                    - id: "lifecycle-rule-1"
                      enabled: true
                      expirationInDays: 365
                      transitions:
                          - targetStorageClass: "cool"
                            transitionInDays: 30
            logging:
                destinationBucket: "${variables.logsBucket}"
                logFilePrefix: "logs/"
            versioning:
                status: "Enabled"
            replication:
                enabled: true
                regions: ["us-west-2", "us-east-1"]
            website:
                mainPageDocument: "index.html"
                notFoundDocument: "404.html"
```

## Storage Class Mappings

To simplify object lifecycle configuration, the concept of `hot`, `cool` and `archive` storage classes for object transitions is used for a `celerity/bucket` resource. (This is the simplified model provided by Azure Blob Storage)

Google Cloud Storage and Amazon S3 have more granular sets of storage classes. The following table shows the mapping of storage classes to the simplified model:

| Celerity Bucket Storage Class | Google Cloud Storage | Amazon S3   | Azure Blob Storage |
| ----------------------------- | -------------------- | ----------- | ------------------ |
| hot                           |  STANDARD            | STANDARD    |  hot               |
| cool                          |  NEARLINE            | GLACIER_IR  |  cool              |
| archive                       |  ARCHIVE             | GLACIER     |  archive           |

<Callout title="Limited support in current v0" type="warning">
Only Amazon S3 is supported in the current iteration of Celerity v0.
</Callout>

## Target Environments

### Celerity::1

âœ… **Available in v0**

In the Celerity::1 local environment, object storage is provided by a [minio](https://min.io/) instance running on a container network on the local or CI machine.
Replication and encryption configuration will be ignored in the Celerity::1 environment.

Bucket notifications are published from the minio instance to a [valkey](https://github.com/valkey-io/valkey) queue on the local or CI machine using the [Redis bucket notification](https://min.io/docs/minio/linux/administration/monitoring/publish-events-to-redis.html) support in minio. The runtime will poll the queue for notifications and trigger handlers in response to bucket events.

<Callout title="Note" type="info">
[valkey](https://github.com/valkey-io/valkey) is also used as the `celerity/queue` and `celerity/topic` implementation in Celerity::1, so the same behaviour is mostly reused for bucket notifications.
</Callout>

<Callout title="No encryption in local & CI environments" type="warning">
Buckets are not encrypted in local & CI environment.
</Callout>

### AWS

âœ… **Available in v0**

In AWS, the `celerity/bucket` resource is implemented using [Amazon S3](https://docs.aws.amazon.com/s3/) buckets.

When replication is enabled, Celerity will create a replication configuration for the bucket with a simple rule to replicate objects to the specified regions.
A bucket resource will be created in each of the specified regions in the same storage class as the primary bucket.

Prefix-based replication is not supported in AWS, so all objects in the bucket will be replicated to the specified regions.

If enabling replication for an existing bucket, you will need to initiate a batch replication job to copy existing objects to the replicated buckets, Celerity (or the underlying S3 service) will not automatically copy existing objects to the replicated buckets.

### Google Cloud

ðŸš€ **Planned for v1** - The Google Cloud deployment target is planned for v1, it may become available in a future v0 evolution.

In Google Cloud, the `celerity/bucket` resource is implemented using [Google Cloud Storage](https://cloud.google.com/storage) buckets.

When replication is enabled, Celerity will create a dual-region replication configuration for the bucket with the region for the deployment of the bucket and a single region to replicate to.

<Callout title="Warning" type="warning">
When more than one region is specified for replication, only the first region will be used, as Celerity only supports dual-region replication for Google Cloud Storage buckets.
</Callout>

### Azure

ðŸš€ **Planned for v1** - The Azure deployment target is planned for v1, it may become available in a future v0 evolution.

In Azure, the `celerity/bucket` resource is implemented using [Azure Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/).

When replication is enabled, Celerity will create a replication configuration for the container with a simple rule to replicate objects to the specified regions.

A storage account will be created in each of the specified regions, and the container will be created in each of the storage accounts. A replication policy will be created to replicate objects to the configured regions.

Prefix-based replication is not supported in Azure Blob Storage, so all objects in the container will be replicated to the specified regions.

When updating an existing bucket with replication enabled, Celerity will set a `minCreationTime` (based on the time the container was created) on the replication policy to ensure existing and new objects are replicated to the specified regions.

<Callout title="Azure supports up to 2 regions for replication" type="warning">
When more than two regions are specified for replication, only the first two regions will be used, as Azure Blob Storage only supports replication to two regions (storage accounts).
</Callout>

## App Deploy Configuration

Configuration specific to a target environment can be defined for `celerity/bucket` resources in the [app deploy configuration](/docs/cli/app-deploy-configuration) file.

This section lists the configuration options that can be set in the `deployTarget.config` object in the app deploy configuration file.

### AWS Configuration Options

âœ… **Available in v0**

#### aws.s3.replication.role

The IAM role to assume when replicating objects in an S3 bucket.

**Type**

string

**Deploy Targets**

`aws`, `aws-serverless`

**Default Value**

When not provided, a role to assume will be created automatically when the bucket is created.

**Example**

```javascript
{
  "deployTarget": {
    "name": "aws",
    "appEnv": "production",
    "config": {
      "aws.s3.replication.role": "arn:aws:iam::123456789012:role/my-replication-role"
    }
  }
}
```

#### aws.s3.\<bucketName\>.replication.role

The IAM role to assume when replicating objects in an S3 bucket with a specific name.
`<bucketName>` refers to the logical name (key) of the bucket resource in the blueprint, not the actual name of the bucket in the target environment.

**Type**

string

**Deploy Targets**

`aws`, `aws-serverless`

**Default Value**

When not provided, a role to assume will be created automatically when the bucket is created.

**Example**

```javascript
{
  "deployTarget": {
    "name": "aws",
    "appEnv": "production",
    "config": {
      "aws.s3.myAppBucket.replication.role": "arn:aws:iam::123456789012:role/my-replication-role"
    }
  }
}
```

[^1]: FaaS stands for Function-as-a-Service, which is a serverless compute model where applications are composed of functions that are triggered by events. Examples of FaaS include AWS Lambda, Google Cloud Functions and Azure Functions.
